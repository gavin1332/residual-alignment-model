weighted_alpaca_eval_qwen25_72b_int4_harmless:
  prompt_template: "weighted_alpaca_eval_qwen25_72b_int4_harmless/alpaca_eval_harmlessness_clf.txt"
  fn_completions: "openai_completions"
  completions_kwargs:
    model_name: "/private/model/Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4" #"Qwen2.5-72B-Instruct-GPTQ-Int4"
    max_tokens: 1
    temperature: 1 # temperature should be applied for sampling, so that should make no effect.
    logprobs: true
    top_logprobs: 5
    client_kwargs:
      base_url: "http://10.11.3.28:9998/v1/"
  fn_completion_parser: "logprob_parser"
  completion_parser_kwargs:
    numerator_token: "m"
    denominator_tokens: ["m", "M"]
    is_binarize: false
  completion_key: "completions_all"
  batch_size: 1
